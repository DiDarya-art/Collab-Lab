{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiDarya-art/Collab-Lab/blob/main/Lab%20with%20cat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dvAtaqazyRwd",
      "metadata": {
        "id": "dvAtaqazyRwd"
      },
      "source": [
        "# Лабораторная работа 3\n",
        "### Выполнил: ФИО"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yofx1EqkyRwf",
      "metadata": {
        "id": "yofx1EqkyRwf"
      },
      "source": [
        "Добро пожаловать в третью лабораторную работу!\n",
        "Оформите ваше решение контеста Kaggle в соответствии с этим шаблоном. Ваша задача - показать проверяющим ход ваших рассуждений, поэтому советуем писать много комментариев к коду и приводить комментарии к логике на каждом этапе в текстовых ячейках.\n",
        "Где необходимо, используйте графики для большей наглядности."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DcgwNcDYyRwg",
      "metadata": {
        "id": "DcgwNcDYyRwg"
      },
      "source": [
        "При отправке поменяйте название файла на ваши ФИО!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "emfhBTt4yRwg",
      "metadata": {
        "id": "emfhBTt4yRwg"
      },
      "source": [
        "### Настройка Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NxgLH7b9yRwg",
      "metadata": {
        "id": "NxgLH7b9yRwg"
      },
      "source": [
        "Подключение вашего гугл диска (советуем сохранять все важные артефакты именно на диск, чтобы они не удалились при закрытии вкладки с ноутбуком)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YqN49embyRwg",
      "metadata": {
        "id": "YqN49embyRwg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mWKJZoRmyRwh",
      "metadata": {
        "id": "mWKJZoRmyRwh"
      },
      "source": [
        "Если вы используете google colab и загрузка датасета занимает больше минуты - раскомментируйте и выполните эту ячейку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tiSX2ddfyRwh",
      "metadata": {
        "id": "tiSX2ddfyRwh"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import os\n",
        "\n",
        "# def download_contest3_data():\n",
        "#   # !mkdir ~/.kaggle # закоментить если ругается\n",
        "#   # !touch ~/.kaggle/kaggle.json # закоментить если ругается\n",
        "\n",
        "#   # токен надо сгенерировать в личном кабинете на kaggle (https://www.kaggle.com/settings/account)\n",
        "#   api_token = {\"username\":\"fokuspokus\",\"key\":\"abrakadabra\"}\n",
        "#   with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "#       json.dump(api_token, file)\n",
        "\n",
        "#   !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "#   !kaggle competitions download -p /content/drive/MyDrive/ -c ml-mipt-2023-contest-3\n",
        "\n",
        "#   if not os.path.isdir(\"/content/drive/MyDrive/contest3\"):\n",
        "#     !mkdir /content/drive/MyDrive/contest3\n",
        "\n",
        "#   !unzip /content/drive/MyDrive/ml-mipt-2023-contest-3.zip -d /content/drive/MyDrive/contest3\n",
        "\n",
        "# download_contest3_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y2jDGff4a7gG",
      "metadata": {
        "id": "y2jDGff4a7gG"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/contest3 /content/contest3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kCGDBm-xyRwi",
      "metadata": {
        "id": "kCGDBm-xyRwi"
      },
      "source": [
        "### EDA (исследовательский анализ данных)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yj46NC0SyRwi",
      "metadata": {
        "id": "Yj46NC0SyRwi"
      },
      "source": [
        "В этой лабораторной вы работаете с картинками. Напишите функцию, которая отрисовывала бы ключевые точки на конкретном изображении, это вам пригодится для дебага.\n",
        "Можете посчитать статистики по картинкам в датасете."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подключение библиотек:"
      ],
      "metadata": {
        "id": "fZYsJOsx8lLt"
      },
      "id": "fZYsJOsx8lLt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f5053b3",
      "metadata": {
        "id": "8f5053b3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70cd8df5",
      "metadata": {
        "id": "70cd8df5"
      },
      "source": [
        "Фиксирование seed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566a9623",
      "metadata": {
        "id": "566a9623"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b445e2ee",
      "metadata": {
        "id": "b445e2ee"
      },
      "source": [
        "Рассмотрим данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KDnuBIeqyRwj",
      "metadata": {
        "id": "KDnuBIeqyRwj"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = \"contest3/train_labels.csv\"\n",
        "IMAGE_TRAIN_PATH = \"contest3/images/train\"\n",
        "IMAGE_TEST_PATH = \"contest3/images/test\"\n",
        "TARGET_SIZE = 224\n",
        "train_data = pd.read_csv(TRAIN_PATH)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc304df",
      "metadata": {
        "id": "0dc304df"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d775eff",
      "metadata": {
        "id": "7d775eff"
      },
      "outputs": [],
      "source": [
        "keypoints = train_data.columns[:-1]\n",
        "keypoints"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfdda6bd",
      "metadata": {
        "id": "cfdda6bd"
      },
      "source": [
        "Подберём разные цвета для точек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80acd991",
      "metadata": {
        "id": "80acd991"
      },
      "outputs": [],
      "source": [
        "DEFAULT_POINT_COLORS = [\n",
        "    (255, 0, 0), (150, 0, 0), (255, 0, 255),\n",
        "    (150, 255, 0), (0, 255, 0), (0, 150, 0),\n",
        "    (0, 255, 255), (0, 150, 255), (0, 0, 255)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e9cc27",
      "metadata": {
        "id": "d7e9cc27"
      },
      "source": [
        "Функция отрисовки:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_keypoints_on_image(img, keypoints, radius=5, point_colors=DEFAULT_POINT_COLORS):\n",
        "    \"\"\"\n",
        "    Рисует ключевые точки на уже загруженном RGB изображении (img)\n",
        "    Возвращает изменённое изображение\n",
        "    \"\"\"\n",
        "    img_copy = img.copy()\n",
        "    for i in range(0, len(keypoints), 2):\n",
        "        x = int(keypoints[i])\n",
        "        y = int(keypoints[i + 1])\n",
        "        color = point_colors[i//2]\n",
        "        cv2.circle(img_copy, (x, y), radius, color, -1)\n",
        "    return img_copy"
      ],
      "metadata": {
        "id": "uD8sl23XjGKs"
      },
      "id": "uD8sl23XjGKs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68547cc",
      "metadata": {
        "id": "d68547cc"
      },
      "outputs": [],
      "source": [
        "def draw_keypoints(image_path, keypoints, ax, radius=5, point_colors=DEFAULT_POINT_COLORS):\n",
        "    \"\"\"\n",
        "    image_path: путь к картинке\n",
        "    keypoints: массив ключевых точек (18,) [x1, y1, x2, y2, ...]\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = draw_keypoints_on_image(img, keypoints, radius, point_colors)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41dc3f1a",
      "metadata": {
        "id": "41dc3f1a"
      },
      "source": [
        "Пример изображений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1492285c",
      "metadata": {
        "id": "1492285c"
      },
      "outputs": [],
      "source": [
        "sample_rows = train_data.sample(6, random_state=seed)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "for ax, (_, row) in zip(axes.flatten(), sample_rows.iterrows()):\n",
        "    file_name = row[\"file_name\"]\n",
        "    image_path = os.path.join(IMAGE_TRAIN_PATH, file_name)\n",
        "    kp = row[keypoints].to_numpy()\n",
        "    draw_keypoints(image_path, kp, ax)\n",
        "    ax.set_title(file_name)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb801a60",
      "metadata": {
        "id": "fb801a60"
      },
      "source": [
        "Количество изображений и количество полей различны, проверим уникальность file_name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "551f9afc",
      "metadata": {
        "id": "551f9afc"
      },
      "outputs": [],
      "source": [
        "train_data['file_name'].is_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7802dee7",
      "metadata": {
        "id": "7802dee7"
      },
      "source": [
        "Выведем строки с неуникальными значениями filename:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff59a2e7",
      "metadata": {
        "id": "ff59a2e7"
      },
      "outputs": [],
      "source": [
        "duplicates = train_data[train_data.duplicated(subset='file_name', keep=False)]\n",
        "duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dc5d42c",
      "metadata": {
        "id": "5dc5d42c"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
        "for ax, (_, row) in zip(axes.flatten(), duplicates.iterrows()):\n",
        "    file_name = row[\"file_name\"]\n",
        "    image_path = os.path.join(IMAGE_TRAIN_PATH, file_name)\n",
        "    kp = row[keypoints].to_numpy()\n",
        "    draw_keypoints(image_path, kp, ax)\n",
        "    ax.set_title(f\"Index: {row.name}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48bd46a",
      "metadata": {
        "id": "f48bd46a"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.drop(index=[140, 448]).reset_index(drop=True)\n",
        "train_data['file_name'].is_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b21085",
      "metadata": {
        "id": "44b21085"
      },
      "source": [
        "Статистика датасета:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8b4042",
      "metadata": {
        "id": "ee8b4042"
      },
      "outputs": [],
      "source": [
        "train_data[keypoints].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba798f8",
      "metadata": {
        "id": "3ba798f8"
      },
      "source": [
        "Анализ размеров изображений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b302d635",
      "metadata": {
        "id": "b302d635"
      },
      "outputs": [],
      "source": [
        "heights = []\n",
        "widths = []\n",
        "for filename in train_data[\"file_name\"]:\n",
        "    img = cv2.imread(os.path.join(IMAGE_TRAIN_PATH, filename))\n",
        "    h, w, _ = img.shape\n",
        "    heights.append(h)\n",
        "    widths.append(w)\n",
        "\n",
        "print(\"Height:\\nmin:\", min(heights), \" max:\", max(heights))\n",
        "print(\"Width:\\nmin:\", min(widths), \" max:\", max(widths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4aff00",
      "metadata": {
        "id": "eb4aff00"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(widths, heights, alpha=0.5)\n",
        "plt.xlabel(\"Width\")\n",
        "plt.ylabel(\"Height\")\n",
        "plt.title(\"Разброс размеров картинок\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb3e9d2",
      "metadata": {
        "id": "0bb3e9d2"
      },
      "source": [
        "Точки за пределами изображений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "984593b7",
      "metadata": {
        "id": "984593b7"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "for idx, row in train_data.iterrows():\n",
        "    filename = row[\"file_name\"]\n",
        "    image_path = os.path.join(IMAGE_TRAIN_PATH, filename)\n",
        "    h, w, _ = cv2.imread(image_path).shape\n",
        "    out_of_bounds = False\n",
        "    for i in range(0, len(keypoints), 2):\n",
        "        x = row[keypoints[i]]\n",
        "        y = row[keypoints[i + 1]]\n",
        "        if x < 0 or y < 0 or x >= w or y >= h:\n",
        "            out_of_bounds = True\n",
        "            break\n",
        "\n",
        "    if out_of_bounds:\n",
        "        images.append(filename)\n",
        "\n",
        "print(f\"Всего картинок с точками за пределами изображения: {len(images)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "424c7adf",
      "metadata": {
        "id": "424c7adf"
      },
      "source": [
        "Выводы:\n",
        "- Некоторые точки выходят за границу изображения.\n",
        "- Изображения имеют разный размер. Прямой resize к квадратному формату может искажать пропорции, поэтому на этапе препроцессинга необходимо использовать padding с сохранением соотношений сторон.\n",
        "- Большой разброс котов."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j_TWruIXyRwo",
      "metadata": {
        "id": "j_TWruIXyRwo"
      },
      "source": [
        "### Preprocessing (подготовка данных)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7LLQuVxgyRwp",
      "metadata": {
        "id": "7LLQuVxgyRwp"
      },
      "source": [
        "Мы ожидаем, что в этом разделе вы реализуете кастомный класс для подгрузки данных (cоветуем унаследоваться от `torch.utils.data.Dataset`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# КОСЯКИ.  сделал 2 варианта с препроцессом и без, препроцесс вроде ускорил"
      ],
      "metadata": {
        "id": "zpPdxtayM4io"
      },
      "id": "zpPdxtayM4io",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_images(df, src_dir, out_dir, keypoints_cols, target_size=224):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    is_train = df is not None\n",
        "\n",
        "    if is_train:\n",
        "        new_df = df.copy()\n",
        "        filenames = new_df[\"file_name\"].values\n",
        "    else:\n",
        "        filenames = sorted([f for f in os.listdir(src_dir) if f.endswith('.jpg')])\n",
        "\n",
        "    for filename in tqdm(filenames):\n",
        "        img_path = os.path.join(src_dir, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Propblem with {filename}\")\n",
        "            continue\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        scale = target_size / max(h, w)\n",
        "        nw, nh = int(w * scale), int(h * scale)\n",
        "\n",
        "        # Ресайз и паддинг\n",
        "        img_res = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
        "        canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
        "        pad_x, pad_y = (target_size - nw) // 2, (target_size - nh) // 2\n",
        "        canvas[pad_y:pad_y+nh, pad_x:pad_x+nw] = img_res\n",
        "\n",
        "        cv2.imwrite(os.path.join(out_dir, filename), canvas)\n",
        "\n",
        "        if is_train:\n",
        "            idx = new_df[new_df[\"file_name\"] == filename].index[0]\n",
        "            pts = new_df.loc[idx, keypoints_cols].values.astype(np.float32)\n",
        "            pts[0::2] = (pts[0::2] * scale + pad_x) / target_size\n",
        "            pts[1::2] = (pts[1::2] * scale + pad_y) / target_size\n",
        "            new_df.loc[idx, keypoints_cols] = pts\n",
        "\n",
        "    return new_df if is_train else None"
      ],
      "metadata": {
        "id": "wQvwWQ3Rjkxp"
      },
      "id": "wQvwWQ3Rjkxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data224 = prepare_images(train_data, IMAGE_TRAIN_PATH, \"contest3/train224\", keypoints)\n",
        "prepare_images(None, IMAGE_TEST_PATH, \"contest3/test224\", keypoints)"
      ],
      "metadata": {
        "id": "df6zb9wCjr9g"
      },
      "id": "df6zb9wCjr9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CatDataset(Dataset):\n",
        "    def __init__(self, image_dir, data=None, transform=None):\n",
        "        \"\"\"\n",
        "        image_dir: путь к папке с картинками 224x224\n",
        "        data: DataFrame, точки под 224x224\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.is_train = data is not None\n",
        "        if self.is_train:\n",
        "            self.filenames = data[\"file_name\"].values\n",
        "            self.points = data.drop(columns=[\"file_name\"]).values.astype(np.float32)\n",
        "        else:\n",
        "            self.filenames = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        file_name = self.filenames[idx]\n",
        "        img_path = os.path.join(self.image_dir, file_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.transpose(2, 0, 1).astype(np.float32) / 255.0\n",
        "        img = torch.from_numpy(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if not self.is_train:\n",
        "            return img, file_name\n",
        "        return img, torch.from_numpy(self.points[idx])"
      ],
      "metadata": {
        "id": "wrlgrUQwjv0m"
      },
      "id": "wrlgrUQwjv0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(\n",
        "    train_data224,\n",
        "    test_size=0.2,\n",
        "    random_state=seed\n",
        ")\n",
        "datasets = {\n",
        "    'train': CatDataset(\"contest3/train224\", data=train_df),\n",
        "    'val': CatDataset(\"contest3/train224\", data=val_df),\n",
        "    'test': CatDataset(\"contest3/test224\")\n",
        "}"
      ],
      "metadata": {
        "id": "dvBj11lojyqS"
      },
      "id": "dvBj11lojyqS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b30c0ec8",
      "metadata": {
        "id": "b30c0ec8"
      },
      "source": [
        "Проверим работу датасета:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25930a79",
      "metadata": {
        "id": "25930a79"
      },
      "outputs": [],
      "source": [
        "img, points = datasets['train'][0]\n",
        "img_np = img.permute(1, 2, 0).numpy()\n",
        "points = points.numpy() * TARGET_SIZE\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(img_np)\n",
        "for i in range(0, len(points), 2):\n",
        "    plt.scatter(points[i], points[i+1], c='r', s=10)\n",
        "plt.title(\"Dataset image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BJ7qKlhkyRw9",
      "metadata": {
        "id": "BJ7qKlhkyRw9"
      },
      "source": [
        "### Training/evaluation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mPrS7rA2yRw9",
      "metadata": {
        "id": "mPrS7rA2yRw9"
      },
      "source": [
        "В этом разделе напишите функцию, принимающую модель, оптимизатор, кол-во эпох, и т.д, которая осуществляет обучение с заданными параметрами. Подумайте, что функция будет возвращать.\n",
        "\n",
        "Смысл этого раздела в том, чтобы не дублировать код обучения для каждого эксперимента. А еще на такую функцию легко накинуть перебор гиперпараметров..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pnfu25RVyRw9",
      "metadata": {
        "id": "Pnfu25RVyRw9"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, optimizer, num_epochs,\n",
        "                criterion, device, patience_early_stop=5, path=\"best_model.pth\"):\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_mae': [],\n",
        "        'val_mae': []\n",
        "    }\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "        mode='min', factor=0.5, patience=5)\n",
        "    best_val_loss = float('inf')\n",
        "    early_stop_counter = 0\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # train\n",
        "            else:\n",
        "                model.eval()  # validation\n",
        "            run_loss = 0.0\n",
        "            run_mae = 0.0\n",
        "            # Итерация по батчам\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                # Вычисление градиентов происходит только при обучении\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    mae = torch.abs(outputs - labels).mean()\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                run_loss += loss.item() * inputs.size(0)\n",
        "                run_mae += mae.item() * inputs.size(0)\n",
        "            # Вычисление средней ошибки\n",
        "            run_loss = run_loss / len(dataloaders[phase].dataset)\n",
        "            run_mae = run_mae / len(dataloaders[phase].dataset)\n",
        "            history[f'{phase}_loss'].append(run_loss)\n",
        "            history[f'{phase}_mae'].append(run_mae)\n",
        "\n",
        "            if phase == 'val':\n",
        "                # ReduceLROnPlateau\n",
        "                scheduler.step(run_loss)\n",
        "                # Сохранение лучшей модели\n",
        "                if run_loss < best_val_loss:\n",
        "                    best_val_loss = run_loss\n",
        "                    torch.save(model.state_dict(), path)\n",
        "                    early_stop_counter = 0\n",
        "                else:\n",
        "                    early_stop_counter += 1\n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {history['train_loss'][-1]:.4f} | Val Loss: {history['val_loss'][-1]:.4f}\")\n",
        "        # Early stopping\n",
        "        if early_stop_counter >= patience_early_stop:\n",
        "            break\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cu0SP3bqyRw-",
      "metadata": {
        "id": "cu0SP3bqyRw-"
      },
      "source": [
        "### Prediction function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09Zr3X0ryRw-",
      "metadata": {
        "id": "09Zr3X0ryRw-"
      },
      "source": [
        "Реализуйте функцию, которая бы делала предсказания. Функция принимает датасет/даталоадер и модель (мб еще что-то). Эта функция нужна вам, чтобы было удобнее считать метрику (по сути она будет склеивать предсказания из батчей в один массив)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa20d3d2",
      "metadata": {
        "id": "aa20d3d2"
      },
      "outputs": [],
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions.append(outputs.cpu().numpy())\n",
        "            targets.append(labels.cpu().numpy())\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    targets = np.concatenate(targets, axis=0)\n",
        "    return predictions, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61tER9s3yRw_",
      "metadata": {
        "id": "61tER9s3yRw_"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lCzc9bg5yRw_",
      "metadata": {
        "id": "lCzc9bg5yRw_"
      },
      "source": [
        "В этом разделе задаете архитектуры моделей и ставите эксперименты по обучению. Мы ожидаем, что вы зададите модель в виде класса (унаследуетесь от класса `torch.nn.Module`).\n",
        "\n",
        "Если вы ставили много экспериментов, приведите их в хронологическом порядке, чтобы мы увидели эволюцию ваших рассуждений.\n",
        "\n",
        "Мы ожидаем увидеть графики train/val лоссов и метрик для ваших экспериментов. Мы ожидаем увидеть визуализацию примеров предсказаний."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b1bf4e",
      "metadata": {
        "id": "c3b1bf4e"
      },
      "source": [
        "Функция для построения графиков:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9564a4d",
      "metadata": {
        "id": "c9564a4d"
      },
      "outputs": [],
      "source": [
        "def draw_plots(history):\n",
        "    \"\"\"\n",
        "    Строит графики обучения модели\n",
        "    \"\"\"\n",
        "    _, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # График 1: Loss\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
        "    axes[0].set_title('Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # График 2: Columnwise MAE\n",
        "    axes[1].plot(history['train_mae'], label='Train MAE')\n",
        "    axes[1].plot(history['val_mae'], label='Val MAE')\n",
        "    axes[1].set_title('Columnwise MAE')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('MAE')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d72b1fd7",
      "metadata": {
        "id": "d72b1fd7"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(image_path, kp, pred_kp, ax, color=DEFAULT_POINT_COLORS):\n",
        "    darkened_color = []\n",
        "    for c in color:\n",
        "        new_c = tuple(int(max(0, min(255, x * 0.5))) for x in c)\n",
        "        darkened_color.append(new_c)\n",
        "    img = draw_keypoints(image_path, kp, ax, radius=5)\n",
        "    img = draw_keypoints_on_image(img, pred_kp, radius=3, point_colors=darkened_color)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "def compute_mae_px(preds, targets, image_size=224):\n",
        "    \"\"\"\n",
        "    preds, targets: нормализованные [0,1]\n",
        "    Возвращает среднюю ошибку в пикселях\n",
        "    \"\"\"\n",
        "    preds_px = preds * image_size\n",
        "    targets_px = targets * image_size\n",
        "    mae_px = np.abs(preds_px - targets_px).mean()\n",
        "    return mae_px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(seed)\n",
        "dataloaders = {\n",
        "    'train': DataLoader(datasets['train'], batch_size=BATCH_SIZE, shuffle=True,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                        generator=generator),\n",
        "    'val': DataLoader(datasets['val'], batch_size=BATCH_SIZE, shuffle=False,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True),\n",
        "    'test': DataLoader(datasets['test'], batch_size=BATCH_SIZE, shuffle=False,\n",
        "                       num_workers=NUM_WORKERS, pin_memory=True)\n",
        "}"
      ],
      "metadata": {
        "id": "ADQUnGJif0Ym"
      },
      "id": "ADQUnGJif0Ym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "TwSaM54_yRxA",
      "metadata": {
        "id": "TwSaM54_yRxA"
      },
      "source": [
        "#### Эксперимент 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a481b4d1",
      "metadata": {
        "id": "a481b4d1"
      },
      "source": [
        "Создадим простую сверточную нейронную сеть:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v93zOLLbyRxB",
      "metadata": {
        "id": "v93zOLLbyRxB"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_keypoints=18):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((7, 7))\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_keypoints)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.regressor(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5990e783",
      "metadata": {
        "id": "5990e783"
      },
      "source": [
        "Визуализация архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca97528",
      "metadata": {
        "id": "5ca97528"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model1 = SimpleCNN().to(device)\n",
        "summary(model1, input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1e5108",
      "metadata": {
        "id": "8d1e5108"
      },
      "outputs": [],
      "source": [
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4569a961",
      "metadata": {
        "id": "4569a961"
      },
      "outputs": [],
      "source": [
        "xb, yb = next(iter(dataloaders['train']))\n",
        "print(xb.shape)  # [B, 3, H, W]\n",
        "print(yb.shape)  # [B, num_keypoints]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379d3ca0",
      "metadata": {
        "id": "379d3ca0"
      },
      "outputs": [],
      "source": [
        "model1.eval()\n",
        "with torch.no_grad():\n",
        "    out = model1(xb.to(device))\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b3d024",
      "metadata": {
        "id": "c5b3d024"
      },
      "outputs": [],
      "source": [
        "history1 = train_model(model1, dataloaders, optimizer, num_epochs, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e8d585",
      "metadata": {
        "id": "15e8d585"
      },
      "outputs": [],
      "source": [
        "model1.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rRxKsOTGyRxD",
      "metadata": {
        "id": "rRxKsOTGyRxD"
      },
      "source": [
        "#### Эксперимент 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uMeSmVPvyRxD",
      "metadata": {
        "id": "uMeSmVPvyRxD"
      },
      "outputs": [],
      "source": [
        "class IntermediateCNN(nn.Module):\n",
        "    def __init__(self, num_keypoints=18):\n",
        "        super().__init__()\n",
        "        # Вход 224x224\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # 112x112\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # 56x56\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # 28x28\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # 14x14\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((7, 7)) # Фиксируем размер перед FC слоем\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 7 * 7, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_keypoints)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.regressor(self.features(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = IntermediateCNN().to(device)\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "K1d_4sOUit12"
      },
      "id": "K1d_4sOUit12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history2 = train_model(model2, dataloaders, optimizer, num_epochs, criterion, device, patience_early_stop=7, path=\"best_model2_10.pth\")"
      ],
      "metadata": {
        "id": "hJ16JwYepkvI"
      },
      "id": "hJ16JwYepkvI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_plots(history2)"
      ],
      "metadata": {
        "id": "BDt5z7eJ1G7B"
      },
      "id": "BDt5z7eJ1G7B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wclMbthGxe4F"
      },
      "id": "wclMbthGxe4F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_keypoints=18):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 112x112\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 56x56\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 28x28\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((7, 7))\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*7*7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_keypoints)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.regressor(self.features(x))\n"
      ],
      "metadata": {
        "id": "Ll-RyzthvMtY"
      },
      "id": "Ll-RyzthvMtY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model24 = SmallCNN().to(device)\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model24.parameters(), lr=1e-3)\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "822_TP0Jyc8G"
      },
      "id": "822_TP0Jyc8G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history24 = train_model(model24, dataloaders, optimizer, num_epochs, criterion, device, patience_early_stop=7, path=\"best_model2_4.pth\")"
      ],
      "metadata": {
        "id": "F9t5YEqDyiNj"
      },
      "id": "F9t5YEqDyiNj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_plots(history2)"
      ],
      "metadata": {
        "id": "kmby7UyHyyTo"
      },
      "id": "kmby7UyHyyTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53Suena24zhw"
      },
      "id": "53Suena24zhw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IasP6UXW3SSV"
      },
      "id": "IasP6UXW3SSV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallCNN2(nn.Module):\n",
        "    def __init__(self, num_keypoints=18):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 112x112\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 56x56\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 28x28\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((7, 7))\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*7*7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_keypoints)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.regressor(self.features(x))\n"
      ],
      "metadata": {
        "id": "xiSrZJG63SWL"
      },
      "id": "xiSrZJG63SWL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2d = SmallCNN2().to(device)\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model2d.parameters(), lr=1e-3)\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "SiJ5KoMz3Xua"
      },
      "id": "SiJ5KoMz3Xua",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history24 = train_model(model2d, dataloaders, optimizer, num_epochs, criterion, device, patience_early_stop=7, path=\"best_model2_d.pth\")"
      ],
      "metadata": {
        "id": "PeKsp-Ah3Z_n"
      },
      "id": "PeKsp-Ah3Z_n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_plots(history2)"
      ],
      "metadata": {
        "id": "E8oSVwTc3hi3"
      },
      "id": "E8oSVwTc3hi3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2l1po4Vj7xHR"
      },
      "id": "2l1po4Vj7xHR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "A1cxo8w8yRxD",
      "metadata": {
        "id": "A1cxo8w8yRxD"
      },
      "source": [
        "#### Эксперимент 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResCNN(nn.Module):\n",
        "    def __init__(self, num_keypoints: int = 18, base: int = 32, drop2d: float = 0.02, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.base = base\n",
        "\n",
        "        # Stem: 5 каналов -> 32\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(5, base, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(base),\n",
        "            nn.SiLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Блоков делаем поровну: [2, 2, 2, 2]\n",
        "        self.stage1 = nn.Sequential(\n",
        "            ResBlock(base, base, stride=1, drop2d=drop2d),\n",
        "            ResBlock(base, base, stride=1, drop2d=drop2d),\n",
        "        )\n",
        "        self.stage2 = nn.Sequential(\n",
        "            ResBlock(base, base*2, stride=2, drop2d=drop2d),\n",
        "            ResBlock(base*2, base*2, stride=1, drop2d=drop2d),\n",
        "        )\n",
        "        self.stage3 = nn.Sequential(\n",
        "            ResBlock(base*2, base*4, stride=2, drop2d=drop2d),\n",
        "            ResBlock(base*4, base*4, stride=1, drop2d=drop2d), # Убрали лишний блок\n",
        "        )\n",
        "        self.stage4 = nn.Sequential(\n",
        "            ResBlock(base*4, base*8, stride=2, drop2d=drop2d),\n",
        "            ResBlock(base*8, base*8, stride=1, drop2d=drop2d),\n",
        "        )\n",
        "\n",
        "        # Сжатие: base*8 (256 каналов при base=32)\n",
        "        self.compress = nn.Sequential(\n",
        "            nn.Conv2d(base*8, base*4, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(base*4),\n",
        "            nn.SiLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "\n",
        "        # Упрощенная голова: меньше слоев = меньше оверфита\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base*4*4*4, 512), # 128*4*4 = 2048 -> 512\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, num_keypoints) # Сразу выход\n",
        "        )\n",
        "\n",
        "    def _add_coord_channels(self, x):\n",
        "        b, _, h, w = x.shape\n",
        "        ys = torch.linspace(-1, 1, steps=h, device=x.device).view(1, 1, h, 1).expand(b, 1, h, w)\n",
        "        xs = torch.linspace(-1, 1, steps=w, device=x.device).view(1, 1, 1, w).expand(b, 1, h, w)\n",
        "        return torch.cat([x, xs, ys], dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._add_coord_channels(x)\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.compress(x)\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)"
      ],
      "metadata": {
        "id": "Sxgl4hjBwVRE"
      },
      "id": "Sxgl4hjBwVRE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = ResCNN().to(device)\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model2d.parameters(), lr=1e-3)\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "PbBRN8TZ6B66"
      },
      "id": "PbBRN8TZ6B66",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozKLDTR15581"
      },
      "id": "ozKLDTR15581",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LUArcPtQyRxD",
      "metadata": {
        "id": "LUArcPtQyRxD"
      },
      "outputs": [],
      "source": [
        "def postprocess_preds(preds, original_widths, original_heights, target_size=224):\n",
        "    \"\"\"\n",
        "    preds: тензор (N, 18) в диапазоне [0, 1]\n",
        "    returns: тензор с реальными пикселями\n",
        "    \"\"\"\n",
        "    rescaled_preds = preds.copy()\n",
        "    for i in range(len(preds)):\n",
        "        w, h = original_widths[i], original_heights[i]\n",
        "        scale = target_size / max(h, w)\n",
        "        nw, nh = int(w * scale), int(h * scale)\n",
        "        pad_x, pad_y = (target_size - nw) // 2, (target_size - nh) // 2\n",
        "\n",
        "        # Сначала из [0, 1] в [0, 224]\n",
        "        rescaled_preds[i] *= target_size\n",
        "        # Вычитаем паддинг и делим на коэффициент масштаба\n",
        "        rescaled_preds[i, 0::2] = (rescaled_preds[i, 0::2] - pad_x) / scale\n",
        "        rescaled_preds[i, 1::2] = (rescaled_preds[i, 1::2] - pad_y) / scale\n",
        "\n",
        "    return rescaled_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ENkKQ_ZYyRxD",
      "metadata": {
        "id": "ENkKQ_ZYyRxD"
      },
      "source": [
        "### Evaluation  (оценка качества модели)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S38MwpwwyRxE",
      "metadata": {
        "id": "S38MwpwwyRxE"
      },
      "source": [
        "В этом разделе проводите оценку качества вашей итоговой модели (с помощью prediction function из раздела выше)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4770ad2",
      "metadata": {
        "id": "f4770ad2"
      },
      "source": [
        "добавить преобразования для теста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H7lfIZbCyRxE",
      "metadata": {
        "id": "H7lfIZbCyRxE"
      },
      "outputs": [],
      "source": [
        "# model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pZr7OfFoyRxE",
      "metadata": {
        "id": "pZr7OfFoyRxE"
      },
      "source": [
        "### Conclusion (Выводы)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OoPdrOHmyRxE",
      "metadata": {
        "id": "OoPdrOHmyRxE"
      },
      "source": [
        "В этом разделе описываете полученные результаты и проводите анализ выполненной работы.\n",
        "Что получилось / не получилось и почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea77f8d3",
      "metadata": {
        "id": "ea77f8d3"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}